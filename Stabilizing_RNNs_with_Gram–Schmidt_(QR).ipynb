{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyykgS59Krjn",
    "outputId": "c5ec9a5d-c567-4a44-fe15-25fde374e1a5"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 1 — Imports & Environment Check\n",
    "# ============================================================\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random, math, time, os, sys\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkKfvH9aKvXi"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 2 — Copy Task Dataset\n",
    "# ============================================================\n",
    "class CopyTaskDataset(Dataset):\n",
    "    \"\"\"\n",
    "    產生經典 Copy Task：\n",
    "    [random symbols] + [delimiter 8] + [padding 8]  -->  model outputs the random symbols after delimiter\n",
    "    Symbol set: 0~7  (8 = delimiter/pad)\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len=10, num_samples=20000):\n",
    "        self.seq_len = seq_len\n",
    "        self.num_samples = num_samples\n",
    "        self.vocab = 9  # 0-8 (8 is delimiter/pad)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 隨機產生長度 seq_len 的 0-7 符號\n",
    "        symbols = torch.randint(0, 8, (self.seq_len,), dtype=torch.long)\n",
    "        x = torch.full((2*self.seq_len + 1,), 8, dtype=torch.long)  # 8 = pad / delimiter\n",
    "        x[:self.seq_len] = symbols\n",
    "        x[self.seq_len] = 8  # delimiter 已是 8\n",
    "\n",
    "        # 目標：前 seq_len 步輸出 8，之後輸出 symbols\n",
    "        y = torch.full_like(x, 8)\n",
    "        y[self.seq_len+1:] = symbols\n",
    "        return x, y\n",
    "\n",
    "# 建立資料集 / DataLoader\n",
    "SEQ_LEN = 10\n",
    "BATCH = 128\n",
    "train_ds = CopyTaskDataset(seq_len=SEQ_LEN, num_samples=20000)\n",
    "val_ds   = CopyTaskDataset(seq_len=SEQ_LEN, num_samples=3000)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrvTBTI1LjcV"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 3 — Config & Utility\n",
    "# ============================================================\n",
    "cfg = {\n",
    "    \"input_dim\": 9,          # vocab size\n",
    "    \"hidden_dim\": 128,\n",
    "    \"output_dim\": 9,\n",
    "    \"epochs\": 20,\n",
    "    \"lr\": 1e-3,\n",
    "    \"proj_every\": 1,         # 每幾個 batch 做一次 QR 投影；設 0 表示不投影\n",
    "}\n",
    "\n",
    "def one_hot(x, num_classes):\n",
    "    return F.one_hot(x, num_classes=num_classes).float()\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    pred_labels = pred.argmax(dim=-1)\n",
    "    return (pred_labels == target).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxbTV5oLLmAo"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 4 — Model Definitions\n",
    "# ============================================================\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(cfg[\"input_dim\"], cfg[\"hidden_dim\"], batch_first=True, nonlinearity=\"tanh\")\n",
    "        self.fc  = nn.Linear(cfg[\"hidden_dim\"], cfg[\"output_dim\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T) int64\n",
    "        x_onehot = one_hot(x, cfg[\"input_dim\"])\n",
    "        out, _   = self.rnn(x_onehot)\n",
    "        logits   = self.fc(out)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def orthogonalize_weight(W):\n",
    "    \"\"\"以 QR 分解將 W 投影到最接近的正交矩陣。\n",
    "       W: (H, H) Tensor  (in-place 修改)\"\"\"\n",
    "    with torch.no_grad():\n",
    "        Q, R = torch.linalg.qr(W)\n",
    "        signs = torch.sign(torch.diag(R))\n",
    "        Q *= signs.unsqueeze(0)  # 保留原本列向量方向\n",
    "        W.copy_(Q)\n",
    "\n",
    "class QRRNN(VanillaRNN):\n",
    "    def __init__(self, cfg, proj_every=1):\n",
    "        super().__init__(cfg)\n",
    "        self.proj_every = proj_every\n",
    "        self.step_count = 0\n",
    "\n",
    "    def project_if_needed(self):\n",
    "        if self.proj_every > 0 and self.step_count % self.proj_every == 0:\n",
    "            orthogonalize_weight(self.rnn.weight_hh_l0)\n",
    "        self.step_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwsFCp4fLnWG"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 5 — Training & Evaluation Loops\n",
    "# ============================================================\n",
    "def run_epoch(model, loader, optimizer=None):\n",
    "    is_train = optimizer is not None\n",
    "    total_loss, total_acc, n = 0, 0, 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train(is_train)\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        logits = model(x)                    # (B, T, C)\n",
    "        loss   = criterion(logits.view(-1, cfg[\"output_dim\"]), y.view(-1))\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # 避免極端爆炸\n",
    "            optimizer.step()\n",
    "            if isinstance(model, QRRNN):\n",
    "                model.project_if_needed()    # QR 投影\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_acc  += accuracy(logits, y) * x.size(0)\n",
    "        n          += x.size(0)\n",
    "    return total_loss / n, total_acc / n\n",
    "\n",
    "\n",
    "def train_model(model, name):\n",
    "    model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"])\n",
    "    train_hist, val_hist = [], []\n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        tr_loss, tr_acc = run_epoch(model, train_loader, opt)\n",
    "        va_loss, va_acc = run_epoch(model, val_loader)\n",
    "        train_hist.append((tr_loss, tr_acc))\n",
    "        val_hist.append((va_loss, va_acc))\n",
    "        print(f\"[{name}] Epoch {epoch+1:2d}/{cfg['epochs']}  \"\n",
    "              f\"Train Loss {tr_loss:.3f} Acc {tr_acc:.3f} | \"\n",
    "              f\"Val Loss {va_loss:.3f} Acc {va_acc:.3f}\")\n",
    "    return train_hist, val_hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlvzs9JCLqXm",
    "outputId": "011fd87a-39bb-4dbd-cf74-0b885c517e56"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 6 — Run Experiments\n",
    "# ============================================================\n",
    "vanilla = VanillaRNN(cfg)\n",
    "qr_rnn  = QRRNN(cfg, proj_every=cfg[\"proj_every\"])\n",
    "\n",
    "hist_vanilla = train_model(vanilla, \"Vanilla\")\n",
    "hist_qr      = train_model(qr_rnn,  \"QR-RNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PF2p-ybICV7C",
    "outputId": "ab42ec9c-65fc-47b3-8151-5f6e60aa1838"
   },
   "outputs": [],
   "source": [
    "vanilla_o = VanillaRNN(cfg)\n",
    "nn.init.orthogonal_(vanilla_o.rnn.weight_hh_l0)\n",
    "hist_o = train_model(vanilla_o, \"Ortho-Init-Only\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "kb7S6QWtLsNC",
    "outputId": "83fdc8b5-d95f-4a57-e1c8-4b97b1ba9e5c"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 7 — Plot Results\n",
    "# ============================================================\n",
    "def extract(hist, idx):  # idx=0 for loss, 1 for acc\n",
    "    return [v[idx] for v in hist]\n",
    "\n",
    "epochs = range(1, cfg[\"epochs\"]+1)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs, extract(hist_vanilla[1], 0), label=\"Vanilla RNN (Val)\")\n",
    "axes[0].plot(epochs, extract(hist_qr[1], 0),      label=\"QR-RNN (Val)\")\n",
    "axes[0].set_title(\"Validation Loss\"); axes[0].set_xlabel(\"Epoch\"); axes[0].grid(); axes[0].legend()\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(epochs, extract(hist_vanilla[1], 1), label=\"Vanilla RNN (Val)\")\n",
    "axes[1].plot(epochs, extract(hist_qr[1], 1),      label=\"QR-RNN (Val)\")\n",
    "axes[1].set_title(\"Validation Accuracy\"); axes[1].set_xlabel(\"Epoch\"); axes[1].grid(); axes[1].legend()\n",
    "\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "id": "Cvn87vFnMgCm",
    "outputId": "8a9ce4a7-c84d-49ad-c7da-fb2535ca16ee"
   },
   "outputs": [],
   "source": [
    "\n",
    "def spectral_norm(W):\n",
    "    return torch.linalg.svdvals(W).max().item()\n",
    "\n",
    "def run_with_tracking(model, name, steps=100):\n",
    "    model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    grad_hist, spec_hist = [], []\n",
    "\n",
    "    loader_iter = iter(train_loader)\n",
    "    for step in range(steps):\n",
    "        try:\n",
    "            x, y = next(loader_iter)\n",
    "        except StopIteration:\n",
    "            loader_iter = iter(train_loader)\n",
    "            x, y = next(loader_iter)\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss   = criterion(logits.view(-1, cfg[\"output_dim\"]), y.view(-1))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        grad_norm = 0.0\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                grad_norm += p.grad.norm().item() ** 2\n",
    "        grad_norm = math.sqrt(grad_norm)\n",
    "        grad_hist.append(grad_norm)\n",
    "\n",
    "        opt.step()\n",
    "        if isinstance(model, QRRNN):\n",
    "            model.project_if_needed()\n",
    "\n",
    "        spec_hist.append(spectral_norm(model.rnn.weight_hh_l0.detach().cpu()))\n",
    "\n",
    "    return grad_hist, spec_hist\n",
    "\n",
    "\n",
    "grad_v, spec_v = run_with_tracking(VanillaRNN(cfg), \"Vanilla\")\n",
    "grad_q, spec_q = run_with_tracking(QRRNN(cfg),      \"QR-RNN\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(grad_v, label=\"Vanilla\")\n",
    "plt.plot(grad_q, label=\"QR\")\n",
    "plt.title(\"Grad-Norm over Steps\"); plt.yscale(\"log\"); plt.legend(); plt.grid(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(spec_v, label=\"Vanilla\")\n",
    "plt.plot(spec_q, label=\"QR\")\n",
    "plt.title(\"Spectral Norm  |W_hh|₂ over Steps\"); plt.legend(); plt.grid(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPmppKJcMtdk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
